{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import shuffle\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "train_path = \"/Users/dpap/Documents/UvA/AML/Assignments/Kaggle/pickle/initial_dataset/\"\n",
    "test_path = \"/Users/dpap/Documents/UvA/AML/Assignments/Kaggle/pickle/initial_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images.pkl  train_images.pkl val_fname.pkl\r\n",
      "test_labels.pkl  train_labels.pkl val_images.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls pickle/initial_dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pickle.load(open(train_path+\"train_images.pkl\",\"rb\"))\n",
    "train_labels = pickle.load(open(train_path+\"train_labels.pkl\",\"rb\"))\n",
    "\n",
    "test_images  = pickle.load(open(train_path+\"test_images.pkl\",\"rb\"))\n",
    "test_labels  = pickle.load(open(train_path+\"test_labels.pkl\",\"rb\"))\n",
    "\n",
    "val_images   = pickle.load(open(train_path+\"val_images.pkl\",\"rb\"))\n",
    "val_fname    = pickle.load(open(train_path+\"val_fname.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingImagesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.images[index]\n",
    "        single_label = self.labels[index]\n",
    "        \n",
    "        if self.transform != None:\n",
    "            #image to tensor\n",
    "            tensor = self.transform(single_image)\n",
    "            return (tensor, single_label)\n",
    "        #return image without turning it to tensor\n",
    "        #probably wrong\n",
    "        return (single_image, single_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationImagesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images, transform=None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.images[index]\n",
    "        if self.transform:\n",
    "            #image to tensor\n",
    "            tensor = self.transform(single_image)\n",
    "            return tensor\n",
    "        return single_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_images, train_lbs, test_images=None, test_lbs = None, batch_size = 32):\n",
    "    \n",
    "    train_dataset = TrainingImagesDataset(train_images, train_lbs, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    \n",
    "    if test_images and test_lbs:\n",
    "        print(\"here\")\n",
    "        test_dataset = TrainingImagesDataset(test_images, test_lbs, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    elif test_images:\n",
    "        test_dataset = ValidationImagesDataset(test_images, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    else:\n",
    "        test_dataset = []\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 0)    \n",
    "    \n",
    "    return (train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 32, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 48, 3, padding=1)\n",
    "        #self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Conv2d(48,32,3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(2048, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 121)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "ocean = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ocean.parameters(), lr = 0.001, momentum = 0.9)#, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = create_dataloaders(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    32] loss: 4.794\n",
      "[1,    64] loss: 4.786\n",
      "[1,    96] loss: 4.779\n",
      "[1,   128] loss: 4.768\n",
      "[1,   160] loss: 4.764\n",
      "[1,   192] loss: 4.753\n",
      "[1,   224] loss: 4.745\n",
      "[1,   256] loss: 4.721\n",
      "[1,   288] loss: 4.682\n",
      "[1,   320] loss: 4.550\n",
      "[1,   352] loss: 4.259\n",
      "[1,   384] loss: 4.195\n",
      "[1,   416] loss: 4.155\n",
      "[1,   448] loss: 4.225\n",
      "[1,   480] loss: 4.192\n",
      "[1,   512] loss: 4.195\n",
      "[1,   544] loss: 4.185\n",
      "[1,   576] loss: 4.147\n",
      "[2,    32] loss: 4.138\n",
      "[2,    64] loss: 4.143\n",
      "[2,    96] loss: 4.150\n",
      "[2,   128] loss: 4.154\n",
      "[2,   160] loss: 4.172\n",
      "[2,   192] loss: 4.171\n",
      "[2,   224] loss: 4.134\n",
      "[2,   256] loss: 4.144\n",
      "[2,   288] loss: 4.069\n",
      "[2,   320] loss: 4.115\n",
      "[2,   352] loss: 4.066\n",
      "[2,   384] loss: 3.939\n",
      "[2,   416] loss: 4.027\n",
      "[2,   448] loss: 4.009\n",
      "[2,   480] loss: 3.995\n",
      "[2,   512] loss: 3.946\n",
      "[2,   544] loss: 3.933\n",
      "[2,   576] loss: 3.945\n",
      "[3,    32] loss: 3.931\n",
      "[3,    64] loss: 3.911\n",
      "[3,    96] loss: 3.955\n",
      "[3,   128] loss: 3.890\n",
      "[3,   160] loss: 3.828\n",
      "[3,   192] loss: 3.852\n",
      "[3,   224] loss: 3.843\n",
      "[3,   256] loss: 3.818\n",
      "[3,   288] loss: 3.747\n",
      "[3,   320] loss: 3.721\n",
      "[3,   352] loss: 3.771\n",
      "[3,   384] loss: 3.768\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCH = 25\n",
    "for epoch in range(EPOCH):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, lbs = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = ocean(inputs)\n",
    "        loss = criterion(outputs, lbs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 32 == 31:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 32))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
